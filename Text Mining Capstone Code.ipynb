{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bda816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aba77327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amenities</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>[\"Carbon monoxide alarm\", \"Air conditioning\", ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2708</th>\n",
       "      <td>[\"Carbon monoxide alarm\", \"Baking sheet\", \"Sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>[\"Hangers\", \"Private patio or balcony\", \"Heati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2864</th>\n",
       "      <td>[\"Carbon monoxide alarm\", \"Air conditioning\", ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5728</th>\n",
       "      <td>[\"Carbon monoxide alarm\", \"Shampoo\", \"Free str...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              amenities\n",
       "id                                                     \n",
       "109   [\"Carbon monoxide alarm\", \"Air conditioning\", ...\n",
       "2708  [\"Carbon monoxide alarm\", \"Baking sheet\", \"Sha...\n",
       "2732  [\"Hangers\", \"Private patio or balcony\", \"Heati...\n",
       "2864  [\"Carbon monoxide alarm\", \"Air conditioning\", ...\n",
       "5728  [\"Carbon monoxide alarm\", \"Shampoo\", \"Free str..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = ('LA_listings.csv')\n",
    "df = pd.read_csv(path, header=0, index_col=0)\n",
    "descript = ['amenities']\n",
    "corpus = df[descript]\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2c2b578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "import json\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b5f2e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(corpus):\n",
    "    clean_corpus = []\n",
    "    en_words = set(nltk.corpus.words.words())\n",
    "    en_stopwords = set(stopwords.words('english'))\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    tokenizer = RegexpTokenizer(r'[\\w|!]+')\n",
    "    for row in corpus:\n",
    "        word_tokens = tokenizer.tokenize(row)\n",
    "        word_tokens_lower = [t.lower() for t in word_tokens]\n",
    "        word_tokens_lower_en = [t for t in word_tokens_lower if t in en_words or not t.isalpha()]\n",
    "        word_tokens_no_stops = [t for t in word_tokens_lower_en if not t in en_stopwords]\n",
    "        word_tokens_no_stops_lemmatized = [wordnet_lemmatizer.lemmatize(t) for t in word_tokens_no_stops]\n",
    "        clean_corpus.append(word_tokens_no_stops_lemmatized)\n",
    "    return clean_corpus\n",
    "def nlp_model_pipeline(clean_corpus):\n",
    "    dictionary = Dictionary(clean_corpus)\n",
    "    doc_term_matrix = [dictionary.doc2bow(listing) for listing in clean_corpus]    \n",
    "    return dictionary, doc_term_matrix\n",
    "def LDA_topic_modelling(doc_term_matrix, dictionary, num_topics=3, passes=2):\n",
    "    LDA = LdaModel\n",
    "    ldamodel = LDA(doc_term_matrix, num_topics=num_topics, id2word = dictionary, passes=passes)\n",
    "    return ldamodel\n",
    "def add_topics_to_df(ldamodel, doc_term_matrix, df, new_col, num_topics):\n",
    "    docTopicProbMat = ldamodel[doc_term_matrix]\n",
    "    docTopicProbDf = pd.DataFrame(index=df.index, columns=range(0, num_topics))\n",
    "    for i, doc in enumerate(docTopicProbMat):\n",
    "        for topic in doc:\n",
    "            docTopicProbDf.iloc[i, topic[0]] = topic[1]\n",
    "    docTopicProbDf[new_col] = docTopicProbDf.idxmax(axis=1)\n",
    "    df_topics = docTopicProbDf[new_col]\n",
    "    df_new = pd.concat([df, df_topics], axis=1)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "406cd4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_description = corpus['amenities'].astype(str)\n",
    "new_corpus = preprocess_text(corpus_description)\n",
    "dictionary_description, doc_term_matrix_description = nlp_model_pipeline(new_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1adf94d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel_description = LDA_topic_modelling(doc_term_matrix_description, dictionary_description, num_topics=3, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8c89b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conno\\anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    }
   ],
   "source": [
    "ch = gensimvis.prepare(ldamodel_description, doc_term_matrix_description, dictionary_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d67b6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(ch, 'amenitieslaLDA.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33a15e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x1f7d350ef10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "canvas_width=1280\n",
    "canvas_height=720\n",
    "long_string = ','.join(list(corpus_description))\n",
    "wordcloud = WordCloud(width=canvas_width,height=canvas_height,background_color=\"white\", max_words=50000, contour_width=3, contour_color='steelblue')\n",
    "wordcloud.generate(long_string)\n",
    "wordcloud.to_file('amenitiesLA_wordcloud.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14bf8f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
